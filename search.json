[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "CNN Change Detection",
    "section": "",
    "text": "Este documento tiene como objetivo inicial ir registrando los avances en el proceso de experimentación de la Tesis de Master of Data Science de la Universidad Adolfo Ibáñez.\nSe pretende un sistema sistema de detección de cambio secuencia a diferente nivles.\n\nDetección de diferencias con imágenes tipo radar Sentinel S1\nClasificación Tipo de cambio (Forestal, Turberas, Humedales, etc.) Sentinel S2\nSegmentación Semántica para identificar pertubacionales y poligonizar"
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introducción",
    "section": "",
    "text": "Objetivo Global:\nCrear Sistema de Alerta y Monitoreo Satelital de Áreas de Relevancia Ambiental, identificará cambios en la estructura de la vegetación en humedales urbanos, turberas de Chiloé y el bosque y matorral esclerófilo de la región Metropolitana para ayudar a su preservación.\n\nEn desarrollo…."
  },
  {
    "objectID": "marco.html",
    "href": "marco.html",
    "title": "2  Marco de Referencia",
    "section": "",
    "text": "Definición:\n\nEl término turba debe ser entendido como un sedimento natural de tipo fitógeno, poroso, no consolidado, constituido por materia orgánica parcialmente descompuesta, acumulada en un ambiente saturado de agua. De esta forma, se puede entender al concepto de turbera como un depósito de turba con un espesor de, al menos, 30 cm (Hauser 1996)\n\nFormación:\n\nSegún [Hauser (1996)], el origen de las turberas se encuentra en las eras glaciares del Pleistoceno, cuando grandes extensiones de casquetes glaciares cubrieron el valle central de la Región de Los Lagos, incluyendo a la Isla Grande de Chiloé. El posterior retiro de los glaciares dejó masas de agua tierra adentro, formando los grandes lagos y lagunas glaciares que en la actualidad componen el paisaje de la región.\nEn el caso de Chiloé, zona en la que se establecieron las condiciones climáticas ideales para el desarrollo del musgo del género Sphagnum, lo que permitió la acumulación de materia orgánica en depresiones del relieve de la isla con alto contenido de humedad Figure 2.1 (a). Este proceso de acumulación del musgo se consolidó en la formación de extensas turberas Figure 2.1 (b) y Figure 2.1 (c) . [Hauser (1996)]\n\n\n\n\n\nProceso de formación de turberas de origen glaciar (caso de Chiloé). Fuente: (Schofield W.B 1985)\n\n\n\nBotánicamente (Chiloé):\n\nBotánicamente, el pompón pertenece al Reino de las Plantas, a la División Bryophyta, a la Clase Musci y a la Familia de las Sphagnaceas. Esta familia comprende sólo un género, Sphagnum, compuesto por más de 300 especies descritas. En el archipiélago de Chiloé conviven varias especies de este género. La más abundante es S. magellanicum, que se caracteriza por su color rojo, talla relativamente robusta y hojas con ápice obtuso. Suele cubrir grandes superficies con mal drenaje en terrenos abiertos o cubriendo el suelo de los tepuales (bosques formados por la mirtácea Tepualia stipularis), donde se desarrolla con extraordinario vigor. Existen además, al menos 4 especies que se han identificado en la zona norte de la Isla: S. fimbriatum, S. falcatulum, S. recurvum y S. cuspidatum var. cuspidatum. Adicionalmente, la literatura cita otras 2 especies para la Isla: S. acutifolium y S. subnitens.Todas estas especies son de difícil identificación, siendo su morfología celular y la anatomía foliar la base de su clasificación (Zegers et al. 2006)\n\nCaracterización:\n\nUna de las características relevantes de las turberas de Sphagnum es que presenta una matriz continua superficial de musgos sobre una capa de turba que puede alcanzar varios metros de profundidad (Díaz et al. 2008). Según el mismo autor, entre otras características relevantes de este tipo de turberas se encuentran:\n\nLa turba que la compone es de origen vegetal y se encuentra en distintos estados de descomposición anaeróbica. Figure 2.1\nEl estrato superficial es biológicamente activo, conformado por asociaciones de especies, entre las que predominan plantas con gran capacidad para retener humedad Figure 2.1 (b).\nEl musgo Sphagnum forma un ambiente pobre en nutrientes (baja concentración de nitrógeno), ácido, anóxico y frío, lo que previene la presencia de hongos y bacterias que descomponen al material muerto Figure 2.1 (c).\nTiene una gran capacidad de absorción de agua (hasta 20 veces su peso seco en agua) Figure 2.1 (e)\nSu fuente de agua proviene de ríos y/o de la lluvia Figure 2.1 (d).\nEs un ecosistema de humedal con flora y fauna única y especializada.\n\n\n\n\n\n\n\n\n\n\n(a)\n\n\n\n\n\n\n\n(b)\n\n\n\n\n\n\n\n\n\n(c)\n\n\n\n\n\n\n\n(d)\n\n\n\n\n\n\n\n\n\n(e)\n\n\n\n\n\n\n\n(f)\n\n\n\n\nFigure 2.1: Fuente: (Treimun 2017)\n\n\n\n\nExtracción:\n\nComo Problema …\n\n\n\n\n\n\nDíaz, María F., Juan Larraín, Gabriela Zegers, and Carolina Tapia. 2008. “Floristic and Hydrological Characterization of Chiloé Island Peatlands, Chile.” Revista Chilena de Historia Natural 81 (4): 455–68. https://doi.org/10.4067/S0716-078X2008000400002.\n\n\nHauser, Arturo. 1996. “Los depósitos de turba en Chile y sus perspectivas de utilización.” Revista Geológica de Chile 23 (2) : 217-229., 13. http://www.andeangeology.cl/index.php/revista1/article/view/2208.\n\n\nSchofield W.B. 1985. “Introduction to Bryology.”\n\n\nTreimun, John. 2017. “Turberas de Chiloé, Ministerio del Medio Ambiente, Chile.”\n\n\nZegers, Gabriela, Juan Larraín, María Francisca Díaz, and Juan Armesto. 2006. “Impacto ecológico y social de la explotación de pomponales y turberas de Sphagnum en la Isla Grande de Chiloé.” http://biblioteca.cehum.org/handle/CEHUM2018/1389."
  },
  {
    "objectID": "rev_biblio.html",
    "href": "rev_biblio.html",
    "title": "3  Revisión Bibliográfica",
    "section": "",
    "text": "En está sección se registrará los aspectos generales de la revisión bibliográfica a modo de conocer el estado del arte en técnicas de identificación de cambios en imagenes satelitales utilizado redes neuronales convolucionales."
  },
  {
    "objectID": "rev_biblio.html#detección-de-cambios-con-imágenes-radar",
    "href": "rev_biblio.html#detección-de-cambios-con-imágenes-radar",
    "title": "3  Revisión Bibliográfica",
    "section": "3.1 Detección de Cambios con Imágenes Radar",
    "text": "3.1 Detección de Cambios con Imágenes Radar\n\n3.1.1 Ms-CapsNet\nSAR Image Change Detection Based on Multiscale Capsule Network (Gao et al. 2021)\n\nResumen:\n\nLos métodos tradicionales de detección de cambios en imágenes de radar de apertura sintética basados en redes neuronales convolucionales (CNN) se enfrentan a los retos del ruido de moteado y la sensibilidad a la deformación. Para mitigar estos problemas, propone una red de cápsulas multiescala (Ms-CapsNet) para extraer la información discriminativa entre los píxeles cambiados y los no cambiados. Por un lado, el módulo de cápsula multiescala se emplea para explotar la relación espacial de las características. Por lo tanto, se pueden conseguir propiedades equivariantes agregando las características de diferentes posiciones. Por otro lado, se ha diseñado un módulo de convolución de fusión adaptativa (AFC) para la Ms-CapsNet propuesta. Se pueden capturar características semánticas más altas para las cápsulas primarias. Las características extraídas por el módulo AFC mejoran significativamente la robustez frente al ruido de moteado. La eficacia de la Ms-CapsNet propuesta se verifica en tres conjuntos de datos SAR reales. Los experimentos de comparación con cuatro métodos de vanguardia demuestran la eficacia del método propuesto.\n\nIndex Terms:\n\nChange detection, multiscale capsule network, synthetic aperture radar, deep learning.\n\n\n\n\n\nMs-CapsNet: Ilustración del método de detección de cambios propuesto basado en la red de cápsulas multiescala\n\n\nResultados y Análisis de Experimentos.\n\n\n\nVisualized results of different change detection methods on three datasets. (a) Image captured at t1. (b) Image captured at t2. (c) Ground truth image. (d) Result by PCANet. (e) Result by MLFN. (f) Result by DCNN. (g) Result by LR-CNN. (h) Result by the proposed Ms-CapsNet."
  },
  {
    "objectID": "rev_biblio.html#graph-based-knowledge-supplement",
    "href": "rev_biblio.html#graph-based-knowledge-supplement",
    "title": "3  Revisión Bibliográfica",
    "section": "3.2 Graph-Based Knowledge Supplement",
    "text": "3.2 Graph-Based Knowledge Supplement\nChange Detection From Synthetic Aperture Radar Images via Graph-Based Knowledge Supplement Network (Wang et al. 2022)\n\nResumen:\n\nLa detección de cambios en las imágenes del radar de apertura sintética (SAR) es una tarea vital pero difícil en el campo del análisis de imágenes de teledetección. La mayoría de los trabajos anteriores adoptan un método auto-supervisado que utiliza muestras pseudo-etiquetadas para guiar el entrenamiento y las pruebas subsecuentes. Sin embargo, las redes profundas suelen requerir muchas muestras de alta calidad para la optimización de los parámetros. El ruido en las pseudo-etiquetas afecta inevitablemente al rendimiento final de la detección de cambios. Para resolver el problema, proponemos una red de complemento de conocimiento basada en grafos (GKSNet). Para ser más específicos, extraemos información discriminatoria del conjunto de datos etiquetados existente como conocimiento adicional, para suprimir hasta cierto punto los efectos adversos de las muestras ruidosas. A continuación, diseñamos un módulo de transferencia de grafos para destilar información contextual de forma atenta desde el conjunto de datos etiquetados al conjunto de datos de destino, lo que permite salvar la correlación de características entre los conjuntos de datos. Para validar el método propuesto, realizamos amplios experimentos con cuatro conjuntos de datos de SAR, que demostraron la superioridad de la GKSNet propuesta en comparación con varias líneas de base del estado de la técnica.\n\nIndex Terms:\n\nChange detection, graph dependency fusion, knowledge supplement network, synthetic aperture radar (SAR).\n\n\n\n\n\nSchematic illustration of the proposed GKSNet. The image features extracted by deep CNNs are projected into a graph representation. Then, the graph representations are transferred and fused via graph transfer module across different datasets. Finally, features from different graphs are fused via intergraph fusion module. Through feature fusion, the model exploits the common knowledge and bridge the feature correlation from different datasets. The obtained evolved features are capable of improving the change detection performance."
  },
  {
    "objectID": "rev_biblio.html#detección-de-cambios-con-imágenes-de-alta-resolución",
    "href": "rev_biblio.html#detección-de-cambios-con-imágenes-de-alta-resolución",
    "title": "3  Revisión Bibliográfica",
    "section": "3.3 Detección de Cambios con Imágenes de alta resolución",
    "text": "3.3 Detección de Cambios con Imágenes de alta resolución\n\n3.3.1 DASNet\nDASNet: Dual attentive fully convolutional siamese networks for change detection in high-resolution satellite images(Chen et al. 2021)\n\nResumen:\n\nLa detección de cambios es una tarea básica del procesamiento de imágenes por teledetección. El objetivo de la investigación es identificar la información de cambio de interés y filtrar la información de cambio irrelevante como factores de interferencia. Recientemente, el aumento del aprendizaje profundo ha proporcionado nuevas herramientas para la detección de cambios, que han dado resultados impresionantes. Sin embargo, los métodos disponibles se centran principalmente en la información de diferencia entre las imágenes de teledetección multitemporal y carecen de robustez ante la información de pseudocambio. Para superar la falta de resistencia de los métodos actuales a los pseudocambios, en este trabajo proponemos un nuevo método, a saber, las redes siamesas totalmente convolucionales de atención dual (DASNet), para la detección de cambios en imágenes de alta resolución. A través del mecanismo de atención dual, se capturan las dependencias de largo alcance para obtener representaciones de características más discriminantes para mejorar el rendimiento de reconocimiento del modelo. Además, la muestra desequilibrada es un problema grave en la detección de cambios, es decir, las muestras sin cambios son mucho más abundantes que las muestras con cambios, lo que constituye una de las principales razones de los pseudocambios. Proponemos la pérdida contrastiva ponderada de doble margen para abordar este problema, castigando la atención a los pares de características sin cambios y aumentando la atención a los pares de características con cambios. Los resultados experimentales de nuestro método en el conjunto de datos de detección de cambios (CDD) y en el conjunto de datos de detección de cambios en edificios (BCDD) demuestran que, en comparación con otros métodos de referencia, el método propuesto consigue mejoras máximas del 2,9% y el 4,2%, respectivamente, en la puntuación F1. Nuestra implementación de PyTorch está disponible en https://github.com/lehaifeng/DASNet.\n\nIndex Terms:\n\nChange detection, high-resolution images, dual attention, Siamese network, weighted double-margin contrastive loss.\n\n\n\n\n\n\n\nDASNet: Dual attentive fully convolutional siamese networks for change detection in high-resolution satellite"
  },
  {
    "objectID": "rev_biblio.html#links-por-explorar",
    "href": "rev_biblio.html#links-por-explorar",
    "title": "3  Revisión Bibliográfica",
    "section": "3.4 Links Por explorar",
    "text": "3.4 Links Por explorar\nhttps://courses.spatialthoughts.com/end-to-end-gee.html#module-4-change-detection\n\nhttps://developers.google.com/earth-engine/tutorials/community/detecting-changes-in-sentinel-1-imagery-pt-1\nhttps://www.youtube.com/results?search_query=change+detection+gee\narquiologíahttps://code.earthengine.google.com/?scriptPath=users%2Fdenisberroeta%2FGEE_CIT_dbg%3Acc\n\nhttps://www.youtube.com/watch?v=wDBcTOTAwOc\n\nhttps://www.youtube.com/watch?v=5oONMB0UPWc\nhttps://developers.google.cn/earth-engine/tutorials/tutorial_forest_01\nhttps://appliedsciences.nasa.gov/join-mission/training/english/arset-using-google-earth-engine-land-monitoring-applications\nhttps://appliedsciences.nasa.gov/sites/default/files/2021-06/GEE_Land_Part3.pdf\nhttps://www.youtube.com/watch?v=KyjNhAvQS2s\nhttps://paperswithcode.com/task/change-detection-for-remote-sensing-images\n\nhttps://github.com/likyoo/Siam-NestedUNet\ncontaminación\n\nhttps://appliedsciences.nasa.gov/join-mission/training/english/arset-high-resolution-no2-monitoring-space-tropomi\n\nPrograma de la NASA https://appliedsciences.nasa.gov/join-mission/training/english/arset-using-google-earth-engine-land-monitoring-applications\n\nbigearth net\nsentinel 1 Change detection no supervisado S1 si existe cambio algorimo global, unet - rmask\ntorch geo\n\n\n\n\nChen, Jie, Ziyang Yuan, Jian Peng, Li Chen, Haozhe Huang, Jiawei Zhu, Yu Liu, and Haifeng Li. 2021. “DASNet: Dual Attentive Fully Convolutional Siamese Networks for Change Detection of High Resolution Satellite Images.” IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing 14: 1194–1206. https://doi.org/10.1109/JSTARS.2020.3037893.\n\n\nGao, Yunhao, Feng Gao, Junyu Dong, and Heng-Chao Li. 2021. “SAR Image Change Detection Based on Multiscale Capsule Network.” IEEE Geoscience and Remote Sensing Letters 18 (3): 484–88. https://doi.org/10.1109/LGRS.2020.2977838.\n\n\nWang, Junjie, Feng Gao, Junyu Dong, Shan Zhang, and Qian Du. 2022. “Change Detection from Synthetic Aperture Radar Images via Graph-Based Knowledge Supplement Network.” IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing 15: 1823–36. https://doi.org/10.1109/JSTARS.2022.3146167."
  },
  {
    "objectID": "Ms-CapsNet.html",
    "href": "Ms-CapsNet.html",
    "title": "4  Ms-CapsNet",
    "section": "",
    "text": "Los métodos tradicionales de detección de cambios en imágenes de radar de apertura sintética basados en redes neuronales convolucionales (CNN) se enfrentan a los retos del ruido de moteado y la sensibilidad a la deformación. Para mitigar estos problemas, propusimos una red de cápsulas multiescala (Ms-CapsNet) para extraer la información discriminativa entre los píxeles cambiados y los no cambiados. Por un lado, el módulo de cápsula multiescala se emplea para explotar la relación espacial de las características. Por lo tanto, se pueden conseguir propiedades equivariantes agregando las características de diferentes posiciones. Por otro lado, se diseña un módulo de convolución de fusión adaptativa (AFC) para la Ms-CapsNet propuesta. Se pueden capturar características semánticas más altas para las cápsulas primarias. Las características extraídas por el módulo AFC mejoran significativamente la robustez frente al ruido de moteado. La eficacia de la Ms-CapsNet propuesta se verifica en tres conjuntos de datos SAR reales. Los experimentos de comparación con cuatro métodos de vanguardia demuestran la eficacia del método propuesto.\nRespositorio: https://github.com/summitgao/SAR_CD_MS_CapsNet.\n\n\n\nAunque se han propuesto muchas técnicas, la detección de cambios en las imágenes SAR sigue siendo una tarea difícil. La calidad de la imagen se ve deteriorada por el ruido de moteado que dificulta la interpretación meticulosa de los datos SAR. Se han implementado muchos métodos para abordar el problema del ruido de moteado. Suelen constar de tres pasos:\n\nCoregistro de imágenes: El corregistro de imágenes es una tarea fundamental para establecer las correspondencias espaciales entre las imágenes SAR multitemporales.\nGeneración de imágenes de diferencia (DI) : La DI se genera habitualmente mediante los operadores log- ratio, Gauss-ratio [5] y neighborhood-ratio [6].\nClasificación de DI: la mayoría de las investigaciones se dedican a construir un clasificador robusto. Se trata de una tarea no trivial, ya que un clasificador potente determina directamente la precisión de la detección de cambios.\n\nMuchos investigadores se dedican a desarrollar clasificadores potentes para la detección de cambios. Li et al. [7] diseñaron un algoritmo de clustering de dos niveles para la detección de cambios sin supervisión. En [8], la información de vecindad local se incorpora a la función objetivo de clustering para mejorar el rendimiento de la detección de cambios. Gong et al. [9] desarrollaron un campo aleatorio de Markov (MRF) mejorado basado en el clustering de c-medias difusas (FCM) para suprimir el ruido de moteado. En [4], se emplearon las máquinas de Boltzmann restringidas (RBM) apiladas para la detección de cambios en las imágenes SAR. Aunque los métodos anteriores lograron un rendimiento prometedor, las capacidades de representación de características siguen siendo limitadas.\nEn los últimos años, las redes neuronales convolucionales (CNN) han mejorado mucho el rendimiento de muchas tareas visuales. Se ha demostrado que es bastante eficaz para el aprendizaje robusto de características. Los modelos basados en CNN se han aplicado con éxito en la detección de cambios en imágenes de teledetección [10]. Wang et al. [11] propusieron un marco de CNN de extremo a extremo para aprender características discriminativas de la matriz de afinidad mixta para la detección de cambios.\nMás tarde, se desarrolló el modelado de ruido profundo no supervisado para la detección de cambios en imágenes hiperespectrales [12]. Liu et al. [13] propusieron una elegante CNN local restringida (LR-CNN) para la detección de cambios polarimétricos en SAR. En [14], se aplicó el aprendizaje profundo transferido a la detección de cambios en imágenes SAR de hielo marino basado en CNN. Aunque los métodos basados en CNN han logrado un excelente rendimiento en la detección de cambios, la precisión a veces se deteriora en el caso de la transformación, como las inclinaciones y rotaciones. En concreto, la CNN es incapaz de modelar la relación posicional entre los objetos del suelo.\nMás recientemente, Sabour y Hinton propusieron la red Capsule (CapsNet) para dar solución a los problemas en los que los modelos CNN son inadecuados [15]. En CapsNet, un vector de actividad de cápsulas representa los parámetros de instanciación de la entidad, como la pose, la textura y la deformación. La existencia de entidades se expresa mediante la longitud de los parámetros de instanciación. El mecanismo de enrutamiento dinámico se utiliza para la propagación de la información. Se ha comprobado empíricamente que CapsNet es eficaz para el análisis de imágenes de teledetección [16] [17]. Hasta donde sabemos, la literatura sobre la detección de cambios en SAR basada en CapsNet es muy escasa.\n\n\n\nMs-CapsNet: Ilustración del método de detección de cambios propuesto basado en la red de cápsulas multiescala\n\n\nSostenemos que la debilidad de los enfoques existentes de detección de cambios en imágenes SAR proviene principalmente de dos aspectos: Uno es que la correlación de las características de diferentes posiciones no se puede modelar de forma efectiva. El otro es el ruido intrínseco del moteado en las imágenes SAR. Para hacer frente a los problemas mencionados, se propone una red de cápsulas multiescala (Ms-CapsNet) para extraer la información discriminativa entre las imágenes SAR multitemporales. La Ms-CapsNet propuesta tiene una estructura similar a la Red de Cápsulas [15] sin el operador multiescala y el módulo de Convolución de Fusión Adaptativa (AFC). La Ms-CapsNet proporciona un grupo de parámetros de instanciación para capturar características de diferentes posiciones. Para hacer frente al problema del ruido de moteado, el módulo AFC está diseñado para convertir las intensidades de los píxeles en actividades de las características locales. De este modo, las características locales se vuelven robustas al ruido. Se realizan amplios experimentos con tres conjuntos de datos reales para demostrar la superioridad de nuestro método propuesto sobre cuatro trabajos del estado del arte.\nPara mayor claridad, las principales contribuciones se resumen como sigue:\n\nLa Ms-CapsNet propuesta tiene la capacidad de extraer características robustas de diferentes posiciones. Las propiedades equivariantes se pueden conseguir mediante el módulo de cápsulas. Por lo tanto, la demanda de una gran cantidad de muestras de entrenamiento se reduce por la información correlativa y completa.\nSe diseña un módulo AFC sencillo pero eficaz, que puede convertir eficazmente las intensidades de los píxeles en actividades de características locales. El módulo AFC extrae las características semánticas superiores y enfatiza las significativas mediante una estrategia basada en la atención. Por lo tanto, las características locales de actividad se vuelven más resistentes al ruido y se aceptan inmediatamente como entrada de la cápsula primaria.\nSe han realizado amplios experimentos con tres conjuntos de datos de SAR para validar la eficacia del método propuesto. Además, hemos publicado los códigos y la configuración para facilitar futuras investigaciones en el análisis de imágenes de teledetección multitemporal."
  },
  {
    "objectID": "Ms-CapsNet.html#metodología",
    "href": "Ms-CapsNet.html#metodología",
    "title": "4  Ms-CapsNet",
    "section": "4.2 Metodología",
    "text": "4.2 Metodología\n\n4.2.1 A. Adaptive Fusion Convolution Module (AFC)\n\n\n\nIllustration of the Adaptive Fusion Convolution (AFC) module.\n\n\n\n\n4.2.2 B. Capsule Module"
  },
  {
    "objectID": "Ms-CapsNet.html#resultados-y-análisis-de-experimentos.",
    "href": "Ms-CapsNet.html#resultados-y-análisis-de-experimentos.",
    "title": "4  Ms-CapsNet",
    "section": "4.3 Resultados y Análisis de Experimentos.",
    "text": "4.3 Resultados y Análisis de Experimentos.\n\n\n\nVisualized results of different change detection methods on three datasets. (a) Image captured at t1. (b) Image captured at t2. (c) Ground truth image. (d) Result by PCANet. (e) Result by MLFN. (f) Result by DCNN. (g) Result by LR-CNN. (h) Result by the proposed Ms-CapsNet.\n\n\n\n4.3.1 A. Dataset and Evaluation Criteria\n\n\n4.3.2 B. Parameters Analysis of the Proposed Ms-CapsNet\n\n\n4.3.3 C. Change Detection Results on Three Datasets"
  },
  {
    "objectID": "Ms-CapsNet.html#conclusion",
    "href": "Ms-CapsNet.html#conclusion",
    "title": "4  Ms-CapsNet",
    "section": "4.4 Conclusion",
    "text": "4.4 Conclusion\n\n4.4.1 Referencias\n[1] D. Burnner, G. Lemonie, and L. Bruzzone, “Earthquake damage assess- ment of buildings using VHR optical and SAR imagery,” IEEE Trans. Geosci. Remote Sens., vol. 48, no. 5, pp. 2403–2420, May 2010.\n[2] S. Quan, B. Xiong, D. Xiang, L. Zhao, S. Zhang, and G. Kuang, “Eigenvalue-based urban area extraction using polarimetric SAR data,” IEEE J. Sel. Topics Appl. Earth Observ. Remote Sens., vol. 11, no. 2, pp. 458–471, Feb. 2018.\n[3] R. J. Radke, S. Andra, O. Al-Kofahi, and B. Roysam, “Image change detection algorithms: A systematic survey,” IEEE Trans. Image Process., vol. 14, no. 3, pp. 294–307, Mar. 2005. [4] M. Gong, J. Zhao, J. Liu, Q. Miao, and L. Jiao, “Change detection in synthetic aperture radar images based on deep neural networks,” IEEE Trans. Neural Netw. Learn. Syst., vol. 27, no. 1, pp. 125–138, Jan. 2016.\n[5] B. Hou et al., “Unsupervised change detection in SAR image based on gauss-log ratio image fusion and compressed projection,” IEEE J. Sel. Top. Appl. Earth Obs. Remote Sens., vol. 7, no. 8, pp. 3297–3317, 2014.\n[6] M. Gong, Y. Cao, and Q. Wu, “A neighborhood-based ratio approach for change detection in SAR images,” IEEE Geosci. Remote Sens. Lett., vol. 9, no. 2, pp. 307–311, 2012.\n[7] H. Li, T. Celik, N. Longbotham, and W. J. Emery, “Gabor feature based unsupervised change detection of multitemporal SAR images based on two-level clustering,” IEEE Geosci. Remote Sens. Lett., vol. 12, no. 12, pp. 2458–2462, Dec. 2015.\n[8] L. Jia, M. Li, P. Zhang, Y. Wu, and H. Zhu, “SAR image change detection based on multiple kernel k-means clustering with local- neighborhood information,” IEEE Geosci Remote Sens. Lett., vol. 13, no. 6, pp. 856–860, Jun. 2016.\n[9] M. Gong, Z. Zhou, and J. Ma. “Change detection in synthetic aperture radar images based on image fusion and fuzzy clustering,” IEEE Trans. Image Process., vol. 21, no. 4, pp. 2141–2151, Apr. 2012.\n[10] Q.Liu,R.Hang,H.Song,andZ.Li,“Learningmultiscaledeepfeatures for high-resolution satellite image scene classification,” IEEE Tran. Geosci. Remote Sens., vol. 56, no. 1, pp. 117–126, Jan. 2018.\n[11] Q. Wang, Z. Yuan, Q. Du, and X. Li, “GETNET: a general end-to-end 2-D CNN framework for hyperspectral image change detection,” IEEE Trans. Geosci. Remote Sens., vol. 57, no. 1, pp. 3–13, Jan. 2019.\n[12] X. Li, Z. Yuan, and Q. Wang, “Unsupervised deep noise modeling for hyperspectral image change detection,” Remote Sens., vol. 11, no. 3, 258, Jan. 2019.\n[13] F. Liu, L. Jiao, X. Tang, S. Yang, W. Ma, and B. Hou, “Local restricted convolutional neural network for change detection in polarimetric SAR images,” IEEE Trans. Neural Netw. Learn. Syst., vol. 30, no. 3, pp. 1–16, Mar. 2019.\n[14] Y. Gao, F. Gao, J. Dong, and S. Wang. “Transferred deep learning for sea ice change detection from synthetic aperture radar images,” IEEE Geosci. Remote Sens. Lett., vol. 16, no. 10, pp. 1655–1659, Oct. 2019.\n[15] S. Sabour, N. Frosst, and G. E. Hinton, “Dynamic routing between capsules,” in Proc. Adv. Neural Inf. Process. Syst., 2017, pp. 3859— 3869.\n[16] M. E. Paoletti et al., “Capsule networks for hyperspectral image classi- fication,” IEEE Trans. Geosci. Remote Sens., vol. 57, no. 4, pp. 2145– 2160, Apr. 2019.\n[17] K. Zhu et al., “Deep convolutional capsule network for hyperspectral image spectral and spectral-spatial classification,” Remote Sens., vol. 11, no. 3, pp. 1–28, Mar. 2019, Art. no. 223.\n[18] J.Hu,L.Shen,andG.Sun,“Squeeze-and-excitationnetworks,”inProc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), Jun. 2018, pp. 7132–7141.\n[19] F. Gao, J. Dong, B. Li, and Q. Xu, “Automatic change detection in synthetic aperture radar images based on PCANet,” IEEE Geosci. Remote Sens. Lett., vol. 13, no. 12, pp. 1792–1796, Dec. 2016.\n[20] W. Song, S. Li, L. Fang, and T. Lu, “Hyperspectral image classification with deep feature fusion network,” IEEE Trans. Geosci. Remote Sens., vol. 56, no. 6, pp. 3173–3184, Jun. 2018.\n\n\n\n\nGao, Yunhao, Feng Gao, Junyu Dong, and Heng-Chao Li. 2021. “SAR Image Change Detection Based on Multiscale Capsule Network.” IEEE Geoscience and Remote Sensing Letters 18 (3): 484–88. https://doi.org/10.1109/LGRS.2020.2977838."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Chen, Jie, Ziyang Yuan, Jian Peng, Li Chen, Haozhe Huang, Jiawei Zhu, Yu\nLiu, and Haifeng Li. 2021. “DASNet: Dual\nAttentive Fully Convolutional Siamese Networks for Change Detection of\nHigh Resolution Satellite Images.” IEEE Journal of Selected\nTopics in Applied Earth Observations and Remote Sensing 14:\n1194–1206. https://doi.org/10.1109/JSTARS.2020.3037893.\n\n\nDíaz, María F., Juan Larraín, Gabriela Zegers, and Carolina Tapia. 2008.\n“Floristic and Hydrological Characterization of Chiloé Island\nPeatlands, Chile.” Revista Chilena de Historia Natural\n81 (4): 455–68. https://doi.org/10.4067/S0716-078X2008000400002.\n\n\nGao, Yunhao, Feng Gao, Junyu Dong, and Heng-Chao Li. 2021. “SAR\nImage Change Detection Based on Multiscale Capsule Network.”\nIEEE Geoscience and Remote Sensing Letters 18 (3): 484–88. https://doi.org/10.1109/LGRS.2020.2977838.\n\n\nHauser, Arturo. 1996. “Los depósitos de turba en Chile y sus\nperspectivas de utilización.” Revista Geológica de Chile 23\n(2) : 217-229., 13. http://www.andeangeology.cl/index.php/revista1/article/view/2208.\n\n\nSchofield W.B. 1985. “Introduction to Bryology.”\n\n\nTreimun, John. 2017. “Turberas de Chiloé, Ministerio del Medio\nAmbiente, Chile.”\n\n\nWang, Junjie, Feng Gao, Junyu Dong, Shan Zhang, and Qian Du. 2022.\n“Change Detection from Synthetic Aperture Radar Images via\nGraph-Based Knowledge Supplement Network.” IEEE Journal of\nSelected Topics in Applied Earth Observations and Remote Sensing\n15: 1823–36. https://doi.org/10.1109/JSTARS.2022.3146167.\n\n\nZegers, Gabriela, Juan Larraín, María Francisca Díaz, and Juan Armesto.\n2006. “Impacto ecológico y social de la explotación de pomponales\ny turberas de Sphagnum en la Isla Grande de Chiloé.” http://biblioteca.cehum.org/handle/CEHUM2018/1389."
  }
]