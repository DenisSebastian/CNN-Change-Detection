<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.0.38">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>CNN Change Detection - 4&nbsp; Ms-CapsNet</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./insumos.html" rel="next">
<link href="./rev_biblio.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>


<link rel="stylesheet" href="style.css">
</head>

<body class="nav-sidebar floating slimcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Ms-CapsNet</span></h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">CNN Change Detection</a> 
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">Preface</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./intro.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduccion</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./marco.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Marco de Referencia</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./rev_biblio.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Revisión Bibliográfica</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Ms-CapsNet.html" class="sidebar-item-text sidebar-link active"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Ms-CapsNet</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./insumos.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Insumos</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./experimentacion.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Experimentación</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">References</a>
  </div>
</li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#ms-capsnet-sar-image-change-detection-based-on-multiscale-capsule-network-gao2021" id="toc-ms-capsnet-sar-image-change-detection-based-on-multiscale-capsule-network-gao2021" class="nav-link active" data-scroll-target="#ms-capsnet-sar-image-change-detection-based-on-multiscale-capsule-network-gao2021"> <span class="header-section-number">4.1</span> Ms-CapsNet: SAR Image Change Detection Based on Multiscale Capsule Network <span class="citation" data-cites="gao2021">(<span>Gao et al. 2021</span>)</span></a>
  <ul class="collapse">
  <li><a href="#abstract" id="toc-abstract" class="nav-link" data-scroll-target="#abstract"> <span class="header-section-number">4.1.1</span> Abstract</a></li>
  <li><a href="#introducción" id="toc-introducción" class="nav-link" data-scroll-target="#introducción"> <span class="header-section-number">4.1.2</span> Introducción</a></li>
  </ul></li>
  <li><a href="#metodología" id="toc-metodología" class="nav-link" data-scroll-target="#metodología"> <span class="header-section-number">4.2</span> Metodología</a>
  <ul class="collapse">
  <li><a href="#a.-adaptive-fusion-convolution-module-afc" id="toc-a.-adaptive-fusion-convolution-module-afc" class="nav-link" data-scroll-target="#a.-adaptive-fusion-convolution-module-afc"> <span class="header-section-number">4.2.1</span> A. Adaptive Fusion Convolution Module (AFC)</a></li>
  <li><a href="#b.-capsule-module" id="toc-b.-capsule-module" class="nav-link" data-scroll-target="#b.-capsule-module"> <span class="header-section-number">4.2.2</span> B. Capsule Module</a></li>
  </ul></li>
  <li><a href="#resultados-y-análisis-de-experimentos." id="toc-resultados-y-análisis-de-experimentos." class="nav-link" data-scroll-target="#resultados-y-análisis-de-experimentos."> <span class="header-section-number">4.3</span> Resultados y Análisis de Experimentos.</a>
  <ul class="collapse">
  <li><a href="#a.-dataset-and-evaluation-criteria" id="toc-a.-dataset-and-evaluation-criteria" class="nav-link" data-scroll-target="#a.-dataset-and-evaluation-criteria"> <span class="header-section-number">4.3.1</span> A. Dataset and Evaluation Criteria</a></li>
  <li><a href="#b.-parameters-analysis-of-the-proposed-ms-capsnet" id="toc-b.-parameters-analysis-of-the-proposed-ms-capsnet" class="nav-link" data-scroll-target="#b.-parameters-analysis-of-the-proposed-ms-capsnet"> <span class="header-section-number">4.3.2</span> B. Parameters Analysis of the Proposed Ms-CapsNet</a></li>
  <li><a href="#c.-change-detection-results-on-three-datasets" id="toc-c.-change-detection-results-on-three-datasets" class="nav-link" data-scroll-target="#c.-change-detection-results-on-three-datasets"> <span class="header-section-number">4.3.3</span> C. Change Detection Results on Three Datasets</a></li>
  </ul></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion"> <span class="header-section-number">4.4</span> Conclusion</a>
  <ul class="collapse">
  <li><a href="#referencias" id="toc-referencias" class="nav-link" data-scroll-target="#referencias"> <span class="header-section-number">4.4.1</span> Referencias</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title d-none d-lg-block"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Ms-CapsNet</span></h1>
<p class="subtitle lead">SAR Image Change Detection Based on Multiscale Capsule Network</p>
</div>



<div class="quarto-title-meta">

    
    
  </div>
  

</header>

<section id="ms-capsnet-sar-image-change-detection-based-on-multiscale-capsule-network-gao2021" class="level2 page-columns page-full" data-number="4.1">
<h2 data-number="4.1" class="anchored" data-anchor-id="ms-capsnet-sar-image-change-detection-based-on-multiscale-capsule-network-gao2021"><span class="header-section-number">4.1</span> Ms-CapsNet: SAR Image Change Detection Based on Multiscale Capsule Network <span class="citation" data-cites="gao2021">(<a href="references.html#ref-gao2021" role="doc-biblioref">Gao et al. 2021</a>)</span></h2>
<section id="abstract" class="level3" data-number="4.1.1">
<h3 data-number="4.1.1" class="anchored" data-anchor-id="abstract"><span class="header-section-number">4.1.1</span> Abstract</h3>
<p>Los métodos tradicionales de detección de cambios en imágenes de radar de apertura sintética basados en redes neuronales convolucionales (CNN) se enfrentan a los retos del ruido de moteado y la sensibilidad a la deformación. Para mitigar estos problemas, propusimos una red de cápsulas multiescala (Ms-CapsNet) para extraer la información discriminativa entre los píxeles cambiados y los no cambiados. Por un lado, el módulo de cápsula multiescala se emplea para explotar la relación espacial de las características. Por lo tanto, se pueden conseguir propiedades equivariantes agregando las características de diferentes posiciones. Por otro lado, se diseña un módulo de convolución de fusión adaptativa (AFC) para la Ms-CapsNet propuesta. Se pueden capturar características semánticas más altas para las cápsulas primarias. Las características extraídas por el módulo AFC mejoran significativamente la robustez frente al ruido de moteado. La eficacia de la Ms-CapsNet propuesta se verifica en tres conjuntos de datos SAR reales. Los experimentos de comparación con cuatro métodos de vanguardia demuestran la eficacia del método propuesto.</p>
<p>Respositorio: <a href="https://github.com/summitgao/SAR_CD_MS_CapsNet" class="uri">https://github.com/summitgao/SAR_CD_MS_CapsNet</a>.</p>
</section>
<section id="introducción" class="level3 page-columns page-full" data-number="4.1.2">
<h3 data-number="4.1.2" class="anchored" data-anchor-id="introducción"><span class="header-section-number">4.1.2</span> Introducción</h3>
<p>Aunque se han propuesto muchas técnicas, la detección de cambios en las imágenes SAR sigue siendo una tarea difícil. La calidad de la imagen se ve deteriorada por el ruido de moteado que dificulta la interpretación meticulosa de los datos SAR. Se han implementado muchos métodos para abordar el problema del ruido de moteado. Suelen constar de tres pasos:</p>
<ol type="1">
<li>Coregistro de imágenes: El corregistro de imágenes es una tarea fundamental para establecer las correspondencias espaciales entre las imágenes SAR multitemporales.</li>
<li>Generación de imágenes de diferencia (DI) : La DI se genera habitualmente mediante los operadores log- ratio, Gauss-ratio [5] y neighborhood-ratio [6].</li>
<li>Clasificación de DI: la mayoría de las investigaciones se dedican a construir un clasificador robusto. Se trata de una tarea no trivial, ya que un clasificador potente determina directamente la precisión de la detección de cambios.</li>
</ol>
<p>Muchos investigadores se dedican a desarrollar clasificadores potentes para la detección de cambios. Li et al.&nbsp;[7] diseñaron un algoritmo de clustering de dos niveles para la detección de cambios sin supervisión. En [8], la información de vecindad local se incorpora a la función objetivo de clustering para mejorar el rendimiento de la detección de cambios. Gong et al.&nbsp;[9] desarrollaron un campo aleatorio de Markov (MRF) mejorado basado en el clustering de c-medias difusas (FCM) para suprimir el ruido de moteado. En [4], se emplearon las máquinas de Boltzmann restringidas (RBM) apiladas para la detección de cambios en las imágenes SAR. Aunque los métodos anteriores lograron un rendimiento prometedor, las capacidades de representación de características siguen siendo limitadas.</p>
<p>En los últimos años, las redes neuronales convolucionales (CNN) han mejorado mucho el rendimiento de muchas tareas visuales. Se ha demostrado que es bastante eficaz para el aprendizaje robusto de características. Los modelos basados en CNN se han aplicado con éxito en la detección de cambios en imágenes de teledetección [10]. Wang et al.&nbsp;[11] propusieron un marco de CNN de extremo a extremo para aprender características discriminativas de la matriz de afinidad mixta para la detección de cambios.</p>
<p>Más tarde, se desarrolló el modelado de ruido profundo no supervisado para la detección de cambios en imágenes hiperespectrales [12]. Liu et al.&nbsp;[13] propusieron una elegante CNN local restringida (LR-CNN) para la detección de cambios polarimétricos en SAR. En [14], se aplicó el aprendizaje profundo transferido a la detección de cambios en imágenes SAR de hielo marino basado en CNN. Aunque los métodos basados en CNN han logrado un excelente rendimiento en la detección de cambios, la precisión a veces se deteriora en el caso de la transformación, como las inclinaciones y rotaciones. En concreto, la CNN es incapaz de modelar la relación posicional entre los objetos del suelo.</p>
<p>Más recientemente, Sabour y Hinton propusieron la red Capsule (CapsNet) para dar solución a los problemas en los que los modelos CNN son inadecuados [15]. En CapsNet, un vector de actividad de cápsulas representa los parámetros de instanciación de la entidad, como la pose, la textura y la deformación. La existencia de entidades se expresa mediante la longitud de los parámetros de instanciación. El mecanismo de enrutamiento dinámico se utiliza para la propagación de la información. Se ha comprobado empíricamente que CapsNet es eficaz para el análisis de imágenes de teledetección [16] [17]. Hasta donde sabemos, la literatura sobre la detección de cambios en SAR basada en CapsNet es muy escasa.</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="images/Ms-CapsNet_network.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption margin-caption">Ms-CapsNet: Ilustración del método de detección de cambios propuesto basado en la red de cápsulas multiescala</figcaption><p></p>
</figure>
</div>
<p>Sostenemos que la debilidad de los enfoques existentes de detección de cambios en imágenes SAR proviene principalmente de dos aspectos: Uno es que la correlación de las características de diferentes posiciones no se puede modelar de forma efectiva. El otro es el ruido intrínseco del moteado en las imágenes SAR. Para hacer frente a los problemas mencionados, se propone una red de cápsulas multiescala (Ms-CapsNet) para extraer la información discriminativa entre las imágenes SAR multitemporales. La Ms-CapsNet propuesta tiene una estructura similar a la Red de Cápsulas [15] sin el operador multiescala y el módulo de Convolución de Fusión Adaptativa (AFC). La Ms-CapsNet proporciona un grupo de parámetros de instanciación para capturar características de diferentes posiciones. Para hacer frente al problema del ruido de moteado, el módulo AFC está diseñado para convertir las intensidades de los píxeles en actividades de las características locales. De este modo, las características locales se vuelven robustas al ruido. Se realizan amplios experimentos con tres conjuntos de datos reales para demostrar la superioridad de nuestro método propuesto sobre cuatro trabajos del estado del arte.</p>
<p>Para mayor claridad, las principales contribuciones se resumen como sigue:</p>
<ul>
<li>La Ms-CapsNet propuesta tiene la capacidad de extraer características robustas de diferentes posiciones. Las propiedades equivariantes se pueden conseguir mediante el módulo de cápsulas. Por lo tanto, la demanda de una gran cantidad de muestras de entrenamiento se reduce por la información correlativa y completa.</li>
<li>Se diseña un módulo AFC sencillo pero eficaz, que puede convertir eficazmente las intensidades de los píxeles en actividades de características locales. El módulo AFC extrae las características semánticas superiores y enfatiza las significativas mediante una estrategia basada en la atención. Por lo tanto, las características locales de actividad se vuelven más resistentes al ruido y se aceptan inmediatamente como entrada de la cápsula primaria.</li>
<li>Se han realizado amplios experimentos con tres conjuntos de datos de SAR para validar la eficacia del método propuesto. Además, hemos publicado los códigos y la configuración para facilitar futuras investigaciones en el análisis de imágenes de teledetección multitemporal.</li>
</ul>
</section>
</section>
<section id="metodología" class="level2 page-columns page-full" data-number="4.2">
<h2 data-number="4.2" class="anchored" data-anchor-id="metodología"><span class="header-section-number">4.2</span> Metodología</h2>
<section id="a.-adaptive-fusion-convolution-module-afc" class="level3 page-columns page-full" data-number="4.2.1">
<h3 data-number="4.2.1" class="anchored" data-anchor-id="a.-adaptive-fusion-convolution-module-afc"><span class="header-section-number">4.2.1</span> A. Adaptive Fusion Convolution Module (AFC)</h3>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="images/AFC_module.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption margin-caption">Illustration of the Adaptive Fusion Convolution (AFC) module.</figcaption><p></p>
</figure>
</div>
</section>
<section id="b.-capsule-module" class="level3" data-number="4.2.2">
<h3 data-number="4.2.2" class="anchored" data-anchor-id="b.-capsule-module"><span class="header-section-number">4.2.2</span> B. Capsule Module</h3>
</section>
</section>
<section id="resultados-y-análisis-de-experimentos." class="level2 page-columns page-full" data-number="4.3">
<h2 data-number="4.3" class="anchored" data-anchor-id="resultados-y-análisis-de-experimentos."><span class="header-section-number">4.3</span> Resultados y Análisis de Experimentos.</h2>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="images/Ms-CapsNet-results.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption margin-caption">Visualized results of different change detection methods on three datasets. (a) Image captured at t1. (b) Image captured at t2. (c) Ground truth image. (d) Result by PCANet. (e) Result by MLFN. (f) Result by DCNN. (g) Result by LR-CNN. (h) Result by the proposed Ms-CapsNet.</figcaption><p></p>
</figure>
</div>
<section id="a.-dataset-and-evaluation-criteria" class="level3" data-number="4.3.1">
<h3 data-number="4.3.1" class="anchored" data-anchor-id="a.-dataset-and-evaluation-criteria"><span class="header-section-number">4.3.1</span> A. Dataset and Evaluation Criteria</h3>
</section>
<section id="b.-parameters-analysis-of-the-proposed-ms-capsnet" class="level3" data-number="4.3.2">
<h3 data-number="4.3.2" class="anchored" data-anchor-id="b.-parameters-analysis-of-the-proposed-ms-capsnet"><span class="header-section-number">4.3.2</span> B. Parameters Analysis of the Proposed Ms-CapsNet</h3>
</section>
<section id="c.-change-detection-results-on-three-datasets" class="level3" data-number="4.3.3">
<h3 data-number="4.3.3" class="anchored" data-anchor-id="c.-change-detection-results-on-three-datasets"><span class="header-section-number">4.3.3</span> C. Change Detection Results on Three Datasets</h3>
</section>
</section>
<section id="conclusion" class="level2" data-number="4.4">
<h2 data-number="4.4" class="anchored" data-anchor-id="conclusion"><span class="header-section-number">4.4</span> Conclusion</h2>
<section id="referencias" class="level3" data-number="4.4.1">
<h3 data-number="4.4.1" class="anchored" data-anchor-id="referencias"><span class="header-section-number">4.4.1</span> Referencias</h3>
<p>[1] D. Burnner, G. Lemonie, and L. Bruzzone, “Earthquake damage assess- ment of buildings using VHR optical and SAR imagery,” IEEE Trans. Geosci. Remote Sens., vol.&nbsp;48, no. 5, pp.&nbsp;2403–2420, May 2010.</p>
<p>[2] S. Quan, B. Xiong, D. Xiang, L. Zhao, S. Zhang, and G. Kuang, “Eigenvalue-based urban area extraction using polarimetric SAR data,” IEEE J. Sel. Topics Appl. Earth Observ. Remote Sens., vol.&nbsp;11, no. 2, pp.&nbsp;458–471, Feb.&nbsp;2018.</p>
<p>[3] R. J. Radke, S. Andra, O. Al-Kofahi, and B. Roysam, “Image change detection algorithms: A systematic survey,” IEEE Trans. Image Process., vol.&nbsp;14, no. 3, pp.&nbsp;294–307, Mar.&nbsp;2005. [4] M. Gong, J. Zhao, J. Liu, Q. Miao, and L. Jiao, “Change detection in synthetic aperture radar images based on deep neural networks,” IEEE Trans. Neural Netw. Learn. Syst., vol.&nbsp;27, no. 1, pp.&nbsp;125–138, Jan.&nbsp;2016.</p>
<p>[5] B. Hou et al., “Unsupervised change detection in SAR image based on gauss-log ratio image fusion and compressed projection,” IEEE J. Sel. Top. Appl. Earth Obs. Remote Sens., vol.&nbsp;7, no. 8, pp.&nbsp;3297–3317, 2014.</p>
<p>[6] M. Gong, Y. Cao, and Q. Wu, “A neighborhood-based ratio approach for change detection in SAR images,” IEEE Geosci. Remote Sens. Lett., vol.&nbsp;9, no. 2, pp.&nbsp;307–311, 2012.</p>
<p>[7] H. Li, T. Celik, N. Longbotham, and W. J. Emery, “Gabor feature based unsupervised change detection of multitemporal SAR images based on two-level clustering,” IEEE Geosci. Remote Sens. Lett., vol.&nbsp;12, no. 12, pp.&nbsp;2458–2462, Dec.&nbsp;2015.</p>
<p>[8] L. Jia, M. Li, P. Zhang, Y. Wu, and H. Zhu, “SAR image change detection based on multiple kernel k-means clustering with local- neighborhood information,” IEEE Geosci Remote Sens. Lett., vol.&nbsp;13, no. 6, pp.&nbsp;856–860, Jun.&nbsp;2016.</p>
<p>[9] M. Gong, Z. Zhou, and J. Ma. “Change detection in synthetic aperture radar images based on image fusion and fuzzy clustering,” IEEE Trans. Image Process., vol.&nbsp;21, no. 4, pp.&nbsp;2141–2151, Apr.&nbsp;2012.</p>
<p>[10] Q.Liu,R.Hang,H.Song,andZ.Li,“Learningmultiscaledeepfeatures for high-resolution satellite image scene classification,” IEEE Tran. Geosci. Remote Sens., vol.&nbsp;56, no. 1, pp.&nbsp;117–126, Jan.&nbsp;2018.</p>
<p>[11] Q. Wang, Z. Yuan, Q. Du, and X. Li, “GETNET: a general end-to-end 2-D CNN framework for hyperspectral image change detection,” IEEE Trans. Geosci. Remote Sens., vol.&nbsp;57, no. 1, pp.&nbsp;3–13, Jan.&nbsp;2019.</p>
<p>[12] X. Li, Z. Yuan, and Q. Wang, “Unsupervised deep noise modeling for hyperspectral image change detection,” Remote Sens., vol.&nbsp;11, no. 3, 258, Jan.&nbsp;2019.</p>
<p>[13] F. Liu, L. Jiao, X. Tang, S. Yang, W. Ma, and B. Hou, “Local restricted convolutional neural network for change detection in polarimetric SAR images,” IEEE Trans. Neural Netw. Learn. Syst., vol.&nbsp;30, no. 3, pp.&nbsp;1–16, Mar.&nbsp;2019.</p>
<p>[14] Y. Gao, F. Gao, J. Dong, and S. Wang. “Transferred deep learning for sea ice change detection from synthetic aperture radar images,” IEEE Geosci. Remote Sens. Lett., vol.&nbsp;16, no. 10, pp.&nbsp;1655–1659, Oct.&nbsp;2019.</p>
<p>[15] S. Sabour, N. Frosst, and G. E. Hinton, “Dynamic routing between capsules,” in Proc. Adv. Neural Inf. Process. Syst., 2017, pp.&nbsp;3859— 3869.</p>
<p>[16] M. E. Paoletti et al., “Capsule networks for hyperspectral image classi- fication,” IEEE Trans. Geosci. Remote Sens., vol.&nbsp;57, no. 4, pp.&nbsp;2145– 2160, Apr.&nbsp;2019.</p>
<p>[17] K. Zhu et al., “Deep convolutional capsule network for hyperspectral image spectral and spectral-spatial classification,” Remote Sens., vol.&nbsp;11, no. 3, pp.&nbsp;1–28, Mar.&nbsp;2019, Art. no. 223.</p>
<p>[18] J.Hu,L.Shen,andG.Sun,“Squeeze-and-excitationnetworks,”inProc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), Jun.&nbsp;2018, pp.&nbsp;7132–7141.</p>
<p>[19] F. Gao, J. Dong, B. Li, and Q. Xu, “Automatic change detection in synthetic aperture radar images based on PCANet,” IEEE Geosci. Remote Sens. Lett., vol.&nbsp;13, no. 12, pp.&nbsp;1792–1796, Dec.&nbsp;2016.</p>
<p>[20] W. Song, S. Li, L. Fang, and T. Lu, “Hyperspectral image classification with deep feature fusion network,” IEEE Trans. Geosci. Remote Sens., vol.&nbsp;56, no. 6, pp.&nbsp;3173–3184, Jun.&nbsp;2018.</p>


<div id="refs" class="references csl-bib-body hanging-indent" role="doc-bibliography" style="display: none">
<div id="ref-gao2021" class="csl-entry" role="doc-biblioentry">
Gao, Yunhao, Feng Gao, Junyu Dong, and Heng-Chao Li. 2021. <span>“SAR Image Change Detection Based on Multiscale Capsule Network.”</span> <em>IEEE Geoscience and Remote Sensing Letters</em> 18 (3): 484–88. <a href="https://doi.org/10.1109/LGRS.2020.2977838">https://doi.org/10.1109/LGRS.2020.2977838</a>.
</div>
</div>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      let href = ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./rev_biblio.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Revisión Bibliográfica</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./insumos.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Insumos</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">Copyright 2022, Denis Berroeta</div>   
  </div>
</footer>



</body></html>